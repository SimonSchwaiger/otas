# Standard openCLIP model: https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K
#wget https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K/resolve/main/open_clip_pytorch_model.bin
# MaskCLIP takes original CLIP model
wget https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt